{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "pip install snowflake-connector-python[secure-local-storage,pandas]\n",
    "pip install sqlalchemy\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas\n",
    "import getpass\n",
    "import json\n",
    "\n",
    "from tabulate import tabulate\n",
    "\n",
    "import sqlalchemy.exc\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from sqlalchemy.dialects import registry\n",
    "\n",
    "registry.register('snowflake', 'snowflake.sqlalchemy', 'dialect')\n",
    "\n",
    "SAML_USERNAME = f'{getpass.getuser()}@volvocars.com'  # or SAML_USERNAME = 'cds-id@volvocars.com'\n",
    "engine = create_engine('snowflake://volvocars-manufacturinganalytics' ,connect_args={'user': SAML_USERNAME,'authenticator': 'externalbrowser',})\n",
    "\n",
    "reduced_dataset = False\n",
    "query_rowLimit = \"\" if not reduced_dataset else \" top 1000\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### notebook helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_snowflake(query:str, engine=engine) -> pandas.DataFrame:\n",
    "    \"\"\"Query snowflake and return a pandas dataframe\"\"\"\n",
    "    connection = engine.connect()\n",
    "    try:\n",
    "        _resultSet = pandas.read_sql_query(query, connection)\n",
    "    except (sqlalchemy.exc.ProgrammingError, sqlalchemy.exc.OperationalError) as e:\n",
    "        print(f'Error: {e}')\n",
    "        _resultSet = pandas.DataFrame()\n",
    "    finally:\n",
    "        connection.close()\n",
    "        engine.dispose()\n",
    "    return _resultSet\n",
    "\n",
    "def pivot_and_resample(df: pandas.DataFrame, column_name: str, interval: str) -> pandas.DataFrame:\n",
    "    \"\"\"Pivot and resample a dataframe\"\"\"\n",
    "    df = df.reset_index().pivot_table(index='timestamp', columns=column_name, values='value')\n",
    "    df = df.resample(interval).median()\n",
    "    df = df.round(3)\n",
    "    df.fillna(method='ffill', inplace=True)\n",
    "    df.fillna(method='bfill', inplace=True)\n",
    "    return df\n",
    "\n",
    "def tabulate_table(df: pandas.DataFrame, rows:int = 15) -> None:\n",
    "    \"\"\"Tabulate a dataframe\"\"\"\n",
    "    print(tabulate(df.head(rows).astype(str), headers='keys', tablefmt='pipe', showindex='always', ))\n",
    "\n",
    "class process:\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def detect_pattern(self, input: str):\n",
    "        pattern = re.compile(\n",
    "            r\"^(?:_|B)?\"\n",
    "            + r\"(?P<abbr1>[A-Z]{2}\\B)\"  # VP\n",
    "            + r\"(?P<fake_location>(?P<level>\\d)..[PM]\\d(?:\\d)?)\"  # 413P08\n",
    "            + r\"(?P<abbr2>[A-Z]*)?(?P<numb2>[0-9]*)?\"  # M1\n",
    "            + r\"(?P<abbr3>[A-Z]*)?(?P<numb3>[0-9]*)?\"  # UE1\n",
    "            + r\"(?P<abbr4>[A-Z]*)?(?P<numb4>[0-9]*)?\"\n",
    "        )\n",
    "        match = re.match(pattern, input)\n",
    "        return match.groupdict() if match else {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### query tracking data\n",
    "todo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### query machine metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query definitions from machines\n",
    "query = \"\"\"\n",
    "    select distinct \"a_area\", \"a_process\", \"a_zone\", \"object\", \"a_machinedesc\", \"a_componentdesc\"\n",
    "    from VCG.GB_PLC_300_TELEMETRICS_V1.FROMHMI\n",
    "    where date_trunc('Y',\"timestamp\" ) > '2022'\n",
    "    and \"a_process\" like '%oven%'\n",
    "    and \"a_machinedesc\" is not null\n",
    "    and \"a_machinedesc\" != ''\n",
    "    and \"a_componentdesc\" is not null\n",
    "    and \"a_componentdesc\" != ''\n",
    "    order by \"a_area\", \"a_process\", \"a_zone\"\n",
    "    \"\"\"\n",
    "definitions_machines = query_snowflake(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "definitions_machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for row in definitions_machines, check against process.detect_pattern(row['object'])\n",
    "# if match add \"fake_location\" to row['zone_code']\n",
    "for index, row in definitions_machines.iterrows():\n",
    "    process_object = process()\n",
    "    pattern = process_object.detect_pattern(row['object'])\n",
    "    if pattern:\n",
    "        definitions_machines.loc[index, 'zone_code'] = pattern['fake_location'][1:]\n",
    "    else:\n",
    "        definitions_machines.loc[index, 'zone_code'] = \"\"\n",
    "tabulate_table(definitions_machines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new dataframe, with index zone_code, and join all object that have the same zone_code\n",
    "machine_map = definitions_machines[['zone_code','object', 'a_zone']].copy().drop_duplicates()\n",
    "# order by zone_code\n",
    "machine_map.sort_values(by=['zone_code'], inplace=False)\n",
    "tabulate_table(machine_map, rows=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### query plc function block metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query definitions from function block types and variables\n",
    "query = \"\"\"\n",
    "    select distinct \"property\", \"property_desc\", \"fb_type\", \"fb_description\"\n",
    "    from VCG.GB_PLC_300_TELEMETRICS_V1.FROMHMI\n",
    "    where date_trunc('Y',\"timestamp\" ) > '2022'\n",
    "    and \"a_process\" like '%oven%'\n",
    "    and \"property_desc\" is not null\n",
    "    and \"property_desc\" != ''\n",
    "    \"\"\"\n",
    "definitions_variables = query_snowflake(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabulate_table(definitions_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### variables for query's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of column names\n",
    "wanted_columns = ['timestamp','object','plc','value','unit','property','value_condition']\n",
    "timestamp_columns = [\"\"\"date_part('Y',\"timestamp\" ) year\"\"\", \"\"\"date_part('WEEKISO',\"timestamp\" ) week\"\"\", \"\"\"date_part('DAYOFWEEKISO',\"timestamp\" ) day\"\"\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wanted_ovens = ['electrocoat oven 1','electrocoat oven 2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### resultset actual temperatures\n",
    "joined with process code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query temperature readings\n",
    "query = f\"\"\"\n",
    "    SELECT {query_rowLimit} \"{'\",\"'.join(wanted_columns)}\", {','.join(timestamp_columns)}\n",
    "    FROM VCG.GB_PLC_300_TELEMETRICS_V1.FROMHMI\n",
    "    WHERE \"a_process\" = 'electrocoat oven 1' \n",
    "    AND \"fb_type\" = 'FB1700_LAnInput6Lim'\n",
    "    AND \"a_componentdesc\" = 'Temperature sensor'\n",
    "    and year = '2022'\n",
    "\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultSet = query_snowflake(query)\n",
    "resultSet = resultSet.merge(machine_map[['object','zone_code']], on='object', how='left')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### resultset for setpoints\n",
    "joined with process code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query setpoints\n",
    "query = f\"\"\"\n",
    "    SELECT \"{'\",\"'.join(wanted_columns)}\", {','.join(timestamp_columns)} \n",
    "    FROM VCG.GB_PLC_300_TELEMETRICS_V1.FROMHMI\n",
    "    WHERE \"a_process\" = 'electrocoat oven 1'\n",
    "    AND \"property\" = 'H_SP1'\n",
    "    AND \"unit\" = 'Â°C'\n",
    "    and year = '2022'\n",
    "\n",
    "    \"\"\"\n",
    "resultSet_setpoints = query_snowflake(query)  # resultSet_setpoints.dtypes\n",
    "resultSet_setpoints = resultSet_setpoints.merge(machine_map[['object','zone_code']], on='object', how='left')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### start stop times of oven"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query setpoint index changes (op and close time)\n",
    "query = f\"\"\"\n",
    "    -- open times\n",
    "    select min(\"timestamp\") timestamp, year, week, day, 'start-request' as type\n",
    "    from (\n",
    "        select \"timestamp\",\"object\",\"plc\",\"value\",\n",
    "            lag(\"value\") over ( partition by \"object\" order by \"timestamp\") as previous_value,\n",
    "            \"unit\",\"property\", \"property_desc\",\n",
    "            date_part('Y',\"timestamp\" ) year,\n",
    "            date_part('WEEKISO',\"timestamp\" ) week,\n",
    "            date_part('DAYOFWEEKISO',\"timestamp\" ) day\n",
    "            \n",
    "        from VCG.GB_PLC_300_TELEMETRICS_V1.FROMHMI\n",
    "        where \"a_process\" = 'electrocoat oven 1'\n",
    "        --and \"object\" = 'ER6E1P10VM1'\n",
    "        and \"property\" = 'I_SPReq'\n",
    "        and \"property_desc\" is not null\n",
    "        and \"property_desc\" != ''\n",
    "        and year = '2022'\n",
    "\n",
    "    )\n",
    "    where \"value\" <> previous_value\n",
    "    and previous_value = 0\n",
    "    group by year, week, day\n",
    "    union all\n",
    "    -- closing times\n",
    "    select max(\"timestamp\") timestamp, year, week, day, 'stop-request' as type\n",
    "    from (\n",
    "        select \"timestamp\",\"object\",\"plc\",\"value\",\n",
    "            lead(\"value\") over ( partition by \"object\" order by \"timestamp\") as next_value,\n",
    "            \"unit\",\"property\", \"property_desc\",\n",
    "            date_part('Y',\"timestamp\" ) year,\n",
    "            date_part('WEEKISO',\"timestamp\" ) week,\n",
    "            date_part('DAYOFWEEKISO',\"timestamp\" ) day\n",
    "            \n",
    "        from VCG.GB_PLC_300_TELEMETRICS_V1.FROMHMI\n",
    "        where \"a_process\" = 'electrocoat oven 1'\n",
    "        --and \"object\" = 'ER6E1P10VM1'\n",
    "        and \"property\" = 'I_SPReq'\n",
    "        and \"property_desc\" is not null\n",
    "        and \"property_desc\" != ''\n",
    "        and year = '2022'\n",
    "        \n",
    "    )\n",
    "    where \"value\" <> next_value\n",
    "    and next_value = 0\n",
    "    group by year, week, day\n",
    "\"\"\"\n",
    "\n",
    "resultSet_start_stop = query_snowflake(query)  # resultSet_start_stop.dtypes\n",
    "resultSet_start_stop['date'] = pandas.to_datetime(resultSet_start_stop['timestamp']).dt.date # add date column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create table with start and stop times\n",
    "start_stop_times = resultSet_start_stop.reset_index().pivot(index='date',  columns ='type', values='timestamp')\n",
    "# backfill stop-request\n",
    "start_stop_times['stop-request'] = start_stop_times['stop-request'].fillna(method='bfill')\n",
    "start_stop_times = start_stop_times[start_stop_times['start-request'].notnull()]\n",
    "\n",
    "#remove multi-index\n",
    "start_stop_times = start_stop_times.reset_index()\n",
    "start_stop_times = start_stop_times.set_index('date')\n",
    "\n",
    "# convert to datetime, round to nearest minute\n",
    "start_stop_times['start-request'] = start_stop_times['start-request'].dt.round('min')\n",
    "start_stop_times['stop-request'] = start_stop_times['stop-request'].dt.round('min')\n",
    "\n",
    "tabulate_table(start_stop_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## identify heating sequence\n",
    "1) use start-sequence  -> all zones have temp ok  ->  (5days production) ->  stop-request (X5 bigger)\n",
    "2) use start-sequence  -> all zones have temp ok  -> stop-request\n",
    "\n",
    "\n",
    "production ok = all zones reached setpoint_ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### production ok temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "condition_words = ['Productie','Productie OK','Production OK','Produktie','Produktie OK', 'Start OK']\n",
    "setpoint_ok = pivot_and_resample(resultSet[resultSet['value_condition'].isin(condition_words) & (resultSet['object'] != 'KP6E1P91BT1') | (resultSet['object'] == 'KP6E1P06BT1')], 'zone_code', '12H')\n",
    "setpoint_ok['condition'] = 'setpoint_ok'\n",
    "#tabulate_table(setpoint_ok, rows=15)\n",
    "setpoint_ok\n",
    "setpoint_ok.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setpoint_ok.iloc[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### to low temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_words = ['Laag limiet','Laag','Laag Limiet','Minimum','Te Laag', 'Te laag']\n",
    "setpoint_low = pivot_and_resample(resultSet[resultSet['value_condition'].isin(condition_words)], 'zone_code', '12H' )\n",
    "setpoint_low['condition'] = 'setpoint_low'\n",
    "setpoint_low = setpoint_low[setpoint_low.columns.intersection(setpoint_ok.columns)] # remove columns not in setpoint_ok\n",
    "tabulate_table(setpoint_low, rows=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### to high temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_words = ['Hoog limiet','Hoog','Hoog Limiet','Maximum','Te Hoog', 'Te hoog']\n",
    "setpoint_high = pivot_and_resample(resultSet[resultSet['value_condition'].isin(condition_words)], 'zone_code', '12H' )\n",
    "setpoint_high['condition'] = 'setpoint_high'\n",
    "setpoint_high = setpoint_high[setpoint_high.columns.intersection(setpoint_ok.columns)] # remove columns not in setpoint_ok\n",
    "tabulate_table(setpoint_high, rows=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setpoint temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setpoints = pivot_and_resample(resultSet_setpoints, 'zone_code', '12H' )\n",
    "setpoints = setpoints[setpoints.columns.intersection(setpoint_ok.columns)] # remove columns not in setpoint_ok\n",
    "setpoints['condition'] = 'setpoint'\n",
    "tabulate_table(setpoints, rows=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat all setpoints\n",
    "conditions = pandas.concat([setpoint_ok, setpoint_low, setpoint_high, setpoints])\n",
    "#aggregate all setpoints by condition, drop timestamp\n",
    "conditions = conditions.groupby('condition').median()\n",
    "\n",
    "tabulate_table(conditions, rows=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### actual values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create subset where property is O_AnInputScaled\n",
    "values = pivot_and_resample(resultSet[resultSet['property'] == 'O_AnInputScaled'], 'zone_code', '1min')\n",
    "values = values[values.columns.intersection(setpoint_ok.columns)] # remove columns not in setpoint_ok\n",
    "\n",
    "tabulate_table(values, rows=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setpoint_low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install plotly-resampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in values.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values.columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "import plotly_resampler as pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=values.index, y=values['E1P20'], mode='lines', name='E1P20'))\n",
    "fig.add_trace(go.Scatter(x=values.index, y=values['E1P10'], mode='lines', name='E1P10'))\n",
    "fig.add_trace(go.Scatter(x=values.index, y=values['E1P30'], mode='lines', name='E1P30'))\n",
    "fig.add_trace(go.Scatter(x=values.index, y=values['E1P80'], mode='lines', name='E1P80'))\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "for col in values.columns:\n",
    "    fig.add_trace(go.Scatter(x=values.index, y=values[col], mode='lines', name=col))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#since the temperature of the oven is very uniform the last few hours before starting up, we can use this to check when it suddenly sharply rises and we can tell that the oven was turned on.\n",
    "#If temp rose more than x degrees higher than lowest value of last half hour: oven on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_E1P10 = values['E1P10'].rolling('30min').min()\n",
    "min_E1P10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the table into a pandas DataFrame\n",
    "\n",
    "'''\n",
    "We're only interested in the heating curve.\n",
    "\n",
    "Check the temperature of the last 30 minutes. Right before the oven gets turned on, the temperature is stable and stays about the same value. \n",
    "If the temperature rapidly rises above 6 degrees C compared to the lowest value of the last 30 mins, we can conclude\n",
    "that the oven has been turned on and we tag these values as \"on\". We continue to tag the temp values as \"on\" until we reach the \n",
    "minimum setpoint temperature.\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "list = []\n",
    "\n",
    "for col in values.columns:\n",
    "    df = values.copy()\n",
    "    \n",
    "    #only consider tagging values below this temp value\n",
    "    value = conditions.loc['setpoint_low', col]\n",
    "\n",
    "# Create a new column called \"lowest_E1P10\" and set its value to the lowest value of the \"E1P10\" column in the last 30 minutes for each row\n",
    "    df['lowest_'+col] = df[col].rolling('30min', min_periods=1).min()\n",
    "\n",
    "# Create a new column called \"difference_E1P10\" and set its value to the difference between the value in the \"E1P10\" column and the value in the \"lowest_E1P10\" column for each row\n",
    "    df['difference_'+col] = df[col] - df['lowest_'+col]\n",
    "\n",
    "\n",
    "#if temp is lower than the lowest acceptable setpoint temp (aka setpoint_low), and diff is greater than 3, then oven is on\n",
    "    df.loc[(df[col] < value) & (df['difference_'+col] > 6), col+'on_off'] = 'on'\n",
    "    df.loc[~((df[col] < value) & (df['difference_'+col] > 6)), col+'on_off'] = 'off'\n",
    "    df_col = df\n",
    "    del df\n",
    "    list.append(df_col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = list[1].loc['2022-08-01 23:59:00':'2022-12-31 23:59:00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "col = values.columns[1]\n",
    "# Plot E1P10 values in black\n",
    "fig = px.scatter(df2, x=df2.index, y='E1P10', color_discrete_sequence=['white'])\n",
    "\n",
    "# Plot \"on\" values of E1P10 in red\n",
    "fig.add_scatter(x=df2.index[df2[col+'on_off'] == 'on'], y=df2['E1P10'][df2[col+'on_off'] == 'on'], mode='markers', marker=dict(color='black'))\n",
    "\n",
    "# Set the title and axis labels\n",
    "fig.update_layout(title='E1P10 temp values', xaxis_title='Timestamp', yaxis_title='E1P10 temp (C)')\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list2 = []\n",
    "for df in list:\n",
    "    df3 = df[df.iloc[:, -1] == 'on']\n",
    "    list2.append(df3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list3 = []\n",
    "for df3 in list2:\n",
    "    on_stretches = []\n",
    "    current_stretch = []\n",
    "    for index, row in df3.iterrows():\n",
    "        if not current_stretch:\n",
    "            current_stretch.append(index)\n",
    "        else:\n",
    "            time_diff = index - current_stretch[-1]\n",
    "            if time_diff > pd.Timedelta(minutes=1):\n",
    "                on_stretches.append(current_stretch)\n",
    "                current_stretch = [index]\n",
    "            else:\n",
    "                current_stretch.append(index)\n",
    "    if current_stretch:\n",
    "        on_stretches.append(current_stretch)\n",
    "    list3.append(on_stretches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list3[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list3[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list4=[]\n",
    "for timestamps in list3:\n",
    "    \n",
    "    oven_warmup_times = []\n",
    "    for list in timestamps:\n",
    "        oven_warmup_times.append(len(list))\n",
    "    list4.append(oven_warmup_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list4[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list5 = []\n",
    "for warmup_times in list4:\n",
    "    list6 = []\n",
    "    list6 = [x for x in warmup_times if x >= 5]\n",
    "    list5.append(list6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list5[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(list5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average = sum(oven_warmup_times) / len(oven_warmup_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "conditions_with_oven_temp = conditions.copy()\n",
    "new_row = {'E1P10': average, 'E1P06': 'z', 'E1P20': 'z', 'E1P30': 'x', 'E1P40': 'z', 'E1P50': 'z', 'E1P60': 'x', 'E1P70': 'z', 'E1P80': 'z'}\n",
    "conditions_with_oven_temp.loc[len(conditions_with_oven_temp)] = new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions_with_oven_temp = conditions_with_oven_temp.rename(index={4: 'avg_oven_warmup_time(minutes)'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions_with_oven_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list7 = []\n",
    "for zone in list3:\n",
    "    list8 = []\n",
    "    list8 = [x for x in zone if len(x) >= 5]\n",
    "    list7.append(list8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "max_warmup_times = pd.DataFrame()\n",
    "for i in range(1,(len(list5))):\n",
    "\n",
    "    max_warmup_times[values.columns[i]] = [max(list5[i])]\n",
    "max_warmup_times.rename(index={0: 'max warmup time (minutes)'}, inplace=True)\n",
    "max_warmup_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del times\n",
    "times = pd.DataFrame(columns=['Begin time', 'End time', 'Time difference', 'Begin temp (C)', 'End temp (C)', 'Temperature diff (C)'])\n",
    "times.name = values.columns[1]\n",
    "for interval in list7[1]:\n",
    "    begin_time = interval[0]\n",
    "    end_time = interval[-1]\n",
    "    time_delta = str(end_time - begin_time)[7:]\n",
    "    begin_temp = values.loc[interval[0],times.name]\n",
    "    end_temp = values.loc[interval[-1],times.name]\n",
    "    temp_delta = end_temp - begin_temp\n",
    "    times.loc[len(times)] = [begin_time, end_time, time_delta, begin_temp ,end_temp, temp_delta]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"detected warmup curves for zone:\" + times.name + \"\\n\")\n",
    "times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_file = 'oven_data.xlsx'\n",
    "page_1 = 'measurements'\n",
    "page_2 = 'conditions'\n",
    "page_3 = 'start_stop_times'\n",
    "\n",
    "with pandas.ExcelWriter(excel_file) as writer:\n",
    "    values.to_excel(writer, sheet_name=page_1)\n",
    "    conditions.to_excel(writer, sheet_name=page_2)\n",
    "    start_stop_times.to_excel(writer, sheet_name=page_3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note: *I excelled myself by making this notebook*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
